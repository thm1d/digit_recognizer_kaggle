{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6801da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dependencies\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92108a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Datasets\\Digit Recognizer\\sample_submission.csv\n",
      "..\\Datasets\\Digit Recognizer\\test.csv\n",
      "..\\Datasets\\Digit Recognizer\\test.csv.zip\n",
      "..\\Datasets\\Digit Recognizer\\train.csv\n",
      "..\\Datasets\\Digit Recognizer\\train.csv.zip\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('..\\Datasets\\Digit Recognizer'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca22ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "train_df = pd.read_csv(\"../Datasets/Digit Recognizer/train.csv\")\n",
    "test_df = pd.read_csv(\"../Datasets/Digit Recognizer/test.csv\")\n",
    "train = pd.read_csv(\"../Datasets/Digit Recognizer/train.csv\") \n",
    "test = pd.read_csv(\"../Datasets/Digit Recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa156bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['label']\n",
    "del train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b32894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train_bin = label_binarizer.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0099e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.values\n",
    "X_test = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14bf04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbbed9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = X_train.reshape(X_train.shape[0],28, 28,1).astype('float32')\n",
    "X_test_all = X_test.reshape(X_test.shape[0],28, 28,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dbf75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_bin, test_size=0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67cefde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 123\n",
    "plt.imshow(X_train[index])\n",
    "plt.show()\n",
    "y_train[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51614387",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23932abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 75)        750       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 28, 28, 75)       300       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 75)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 50)        33800     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 14, 50)        0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 14, 14, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 25)          11275     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 7, 7, 25)         100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 25)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               205312    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,867\n",
      "Trainable params: 256,567\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 10 , activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02b6586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "263/263 [==============================] - 128s 482ms/step - loss: 0.1972 - accuracy: 0.9390 - val_loss: 2.5202 - val_accuracy: 0.1294 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "263/263 [==============================] - 115s 439ms/step - loss: 0.0581 - accuracy: 0.9816 - val_loss: 0.1281 - val_accuracy: 0.9699 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "263/263 [==============================] - 95s 362ms/step - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.0534 - val_accuracy: 0.9831 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "263/263 [==============================] - 142s 541ms/step - loss: 0.0333 - accuracy: 0.9889 - val_loss: 0.0411 - val_accuracy: 0.9862 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "263/263 [==============================] - 121s 459ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.0327 - val_accuracy: 0.9895 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "263/263 [==============================] - 119s 451ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0392 - val_accuracy: 0.9876 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "263/263 [==============================] - 126s 479ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.0313 - val_accuracy: 0.9904 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "263/263 [==============================] - 127s 482ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.0610 - val_accuracy: 0.9845 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "263/263 [==============================] - 125s 474ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0629 - val_accuracy: 0.9830 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "263/263 [==============================] - 115s 438ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0407 - val_accuracy: 0.9870 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "263/263 [==============================] - 100s 381ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0311 - val_accuracy: 0.9921 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0341 - val_accuracy: 0.9910 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "263/263 [==============================] - 124s 472ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0411 - val_accuracy: 0.9894 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "263/263 [==============================] - 127s 484ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0373 - val_accuracy: 0.9904 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "263/263 [==============================] - 123s 469ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.0350 - val_accuracy: 0.9912 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "263/263 [==============================] - 136s 518ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.0385 - val_accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "263/263 [==============================] - 147s 559ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0461 - val_accuracy: 0.9886 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "263/263 [==============================] - 116s 442ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0389 - val_accuracy: 0.9900 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "263/263 [==============================] - 105s 401ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0428 - val_accuracy: 0.9896 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "263/263 [==============================] - 103s 393ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.0424 - val_accuracy: 0.9906 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, batch_size = 128 ,epochs = 20 , validation_data = (X_val, y_val) , callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba9f1f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_3l_bn_20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c872dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(predictions,keys,path):\n",
    "    result = pd.DataFrame(\n",
    "        predictions,\n",
    "        columns=['Label'],\n",
    "        index=keys\n",
    "        )\n",
    "    result.index.name='ImageId'\n",
    "    result.to_csv(path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41e07f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 23s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_prob=model.predict(X_test_all) # get predictions for all the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7310c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[np.argmax(pred) for pred in predictions_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c49b1588",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=[i for i in range(1,28001) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a68680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(predictions=labels,keys=keys,path='submission_cnn_3l_bn_20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e753966",
   "metadata": {},
   "source": [
    "Prediction Score on Kaggle: 0.98957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0334057e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
